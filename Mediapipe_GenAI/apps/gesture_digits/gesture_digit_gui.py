import tkinter as tk
from tkinter import ttk
import cv2
import mediapipe as mp
import time
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image, ImageTk, ImageOps
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# === è¨­å®šåƒæ•¸ ===
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# å¾€ä¸Šå…©å±¤æ‰¾åˆ° models è³‡æ–™å¤¾
MODEL_PATH = os.path.abspath(os.path.join(SCRIPT_DIR, '..', '..', 'models', 'gesture_recognizer.task'))
MNIST_MODEL_PATH = os.path.abspath(os.path.join(SCRIPT_DIR, '..', '..', 'models', 'mnist_cnn.pth'))
CONFIDENCE_THRESHOLD = 0.5
BRUSH_COLOR = (0, 255, 255)  # é»ƒè‰²ç•«ç­†
BRUSH_THICKNESS = 15

# === 1. å®šç¾© MNIST æ¨¡å‹æ¶æ§‹ ===
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)
        self.dropout = nn.Dropout(0.25)
        self.fc1 = nn.Linear(64 * 12 * 12, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# === 2. GUI æ‡‰ç”¨ç¨‹å¼ ===
class GestureGUIApp:
    def __init__(self, root):
        self.root = root
        self.root.title("AI æ‰‹å‹¢æ‰‹å¯«è¾¨è­˜ç³»çµ±")
        self.root.geometry("1000x700") # åŠ å¤§ä¸€é»ä»¥å®¹ç´é è¦½
        self.root.protocol("WM_DELETE_WINDOW", self.on_close)

        # åˆå§‹åŒ–è®Šæ•¸
        self.prev_x, self.prev_y = 0, 0
        self.is_drawing = False # ç¹ªåœ–ç‹€æ…‹
        self.canvas_mask = np.zeros((480, 640, 3), dtype=np.uint8) # ç¹ªåœ–å±¤
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # è¼‰å…¥æ¨¡å‹
        self.init_models()

        # å»ºç«‹ UI
        self.create_widgets()

        # å•Ÿå‹•æ”å½±æ©Ÿ
        self.cap = cv2.VideoCapture(1)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        self.update_frame()

    def init_models(self):
        # 1. MNIST
        self.mnist_model = ConvNet().to(self.device)
        if os.path.exists(MNIST_MODEL_PATH):
            self.mnist_model.load_state_dict(torch.load(MNIST_MODEL_PATH, map_location=self.device))
            self.mnist_model.eval()
            print("MNIST æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        else:
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ° MNIST æ¨¡å‹ {MNIST_MODEL_PATH}")

        # 2. MediaPipe
        base_options = python.BaseOptions(model_asset_path=MODEL_PATH)
        options = vision.GestureRecognizerOptions(
            base_options=base_options,
            running_mode=vision.RunningMode.LIVE_STREAM,
            num_hands=1,
            min_hand_detection_confidence=CONFIDENCE_THRESHOLD,
            min_hand_presence_confidence=CONFIDENCE_THRESHOLD,
            min_tracking_confidence=CONFIDENCE_THRESHOLD,
            result_callback=self.mp_callback
        )
        self.recognizer = vision.GestureRecognizer.create_from_options(options)
        self.latest_result = None

    def mp_callback(self, result, output_image, timestamp_ms):
        self.latest_result = result

    def create_widgets(self):
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # å·¦å´ï¼šè¦–è¨Šé¡¯ç¤ºå€
        self.video_label = ttk.Label(main_frame)
        self.video_label.grid(row=0, column=0, rowspan=5, padx=10, pady=10)

        # å³å´ï¼šæ§åˆ¶å€
        control_frame = ttk.LabelFrame(main_frame, text="æ§åˆ¶é¢æ¿")
        control_frame.grid(row=0, column=1, sticky="ns", padx=10, pady=10)

        # ç‹€æ…‹é¡¯ç¤º
        self.lbl_status = ttk.Label(control_frame, text="ç‹€æ…‹: âœ‹ æš«åœä¸­ (åªç§»å‹•æ¸¸æ¨™)", font=("å¾®è»Ÿæ­£é»‘é«”", 12))
        self.lbl_status.pack(pady=10, fill=tk.X)

        ttk.Separator(control_frame, orient='horizontal').pack(fill='x', pady=10)

        # ç¹ªåœ–æ§åˆ¶æŒ‰éˆ• (Toggle)
        self.btn_toggle_draw = tk.Button(control_frame, text="é–‹å§‹ç¹ªåœ– (Start)", bg="lightgreen", font=("Arial", 12, "bold"), command=self.toggle_drawing)
        self.btn_toggle_draw.pack(fill=tk.X, pady=10, ipady=10)

        ttk.Separator(control_frame, orient='horizontal').pack(fill='x', pady=10)

        # è¾¨è­˜çµæœ
        self.lbl_result = ttk.Label(control_frame, text="é æ¸¬æ•¸å­—: ?", font=("Arial", 36, "bold"), foreground="blue")
        self.lbl_result.pack(pady=5)
        
        self.lbl_conf = ttk.Label(control_frame, text="ä¿¡å¿ƒåº¦: 0.0%", font=("Arial", 12))
        self.lbl_conf.pack(pady=5)

        # --- æ–°å¢ï¼šAI è¦–é‡é è¦½ ---
        ttk.Label(control_frame, text="AI è¦–é‡ (28x28):").pack(pady=(10, 0))
        self.lbl_debug_img = ttk.Label(control_frame, relief="solid")
        self.lbl_debug_img.pack(pady=5)
        # åˆå§‹åŒ–ä¸€å€‹ç©ºçš„é»‘è‰²åœ–ç‰‡
        empty_img = Image.new('L', (100, 100), 0)
        self.tk_debug_img = ImageTk.PhotoImage(empty_img)
        self.lbl_debug_img.configure(image=self.tk_debug_img)
        # -----------------------

        ttk.Separator(control_frame, orient='horizontal').pack(fill='x', pady=10)

        # åŠŸèƒ½æŒ‰éˆ•
        btn_recognize = ttk.Button(control_frame, text="âœ¨ è¾¨è­˜ (Recognize)", command=self.recognize_digit)
        btn_recognize.pack(fill=tk.X, pady=5, ipady=10)

        btn_clear = ttk.Button(control_frame, text="ğŸ—‘ï¸ æ¸…é™¤ç•«å¸ƒ (Clear)", command=self.clear_canvas)
        btn_clear.pack(fill=tk.X, pady=5, ipady=10)
        
        ttk.Label(control_frame, text="æ“ä½œèªªæ˜:\n1. é»æ“Šã€Œé–‹å§‹ç¹ªåœ–ã€æŒ‰éˆ•\n2. ç§»å‹•é£ŸæŒ‡æŒ‡å°–å³å¯å¯«å­—\n3. é»æ“Šã€Œæš«åœã€å¯ç§»å‹•ä¸å¯«å­—\n4. é»æ“Šã€Œè¾¨è­˜ã€æŸ¥çœ‹çµæœ", 
                  wraplength=200, foreground="gray").pack(side=tk.BOTTOM, pady=10)

    def toggle_drawing(self):
        self.is_drawing = not self.is_drawing
        if self.is_drawing:
            self.btn_toggle_draw.config(text="æš«åœç¹ªåœ– (Pause)", bg="#ffcccb") # æ·ºç´…è‰²
            self.lbl_status.config(text="ç‹€æ…‹: âœï¸ ç¹ªåœ–ä¸­", foreground="green")
            # é‡ç½®èµ·é»ï¼Œé¿å…ä¸€é»ä¸‹å»å°±é€£ç·šåˆ°ä¸Šæ¬¡çš„ä½ç½®
            self.prev_x, self.prev_y = 0, 0
        else:
            self.btn_toggle_draw.config(text="é–‹å§‹ç¹ªåœ– (Start)", bg="lightgreen")
            self.lbl_status.config(text="ç‹€æ…‹: âœ‹ æš«åœä¸­ (åªç§»å‹•æ¸¸æ¨™)", foreground="black")
            self.prev_x, self.prev_y = 0, 0

    def update_frame(self):
        success, frame = self.cap.read()
        if success:
            # 1. å½±åƒå‰è™•ç†
            frame = cv2.flip(frame, 1)
            h, w, _ = frame.shape
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # 2. MediaPipe æ¨è«–
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            timestamp = time.time_ns() // 1_000_000
            self.recognizer.recognize_async(mp_image, timestamp)

            # 3. è™•ç†è¾¨è­˜çµæœ
            if self.latest_result and self.latest_result.hand_landmarks:
                hand_landmarks = self.latest_result.hand_landmarks[0]
                
                # å–å¾—é£ŸæŒ‡æŒ‡å°–åº§æ¨™ (Index Tip: 8)
                cx = int(hand_landmarks[8].x * w)
                cy = int(hand_landmarks[8].y * h)
                
                # åˆ¤æ–·æ˜¯å¦ç¹ªåœ– (å®Œå…¨ç”±æŒ‰éˆ•ç‹€æ…‹æ±ºå®š)
                if self.is_drawing:
                    if self.prev_x == 0 and self.prev_y == 0:
                        self.prev_x, self.prev_y = cx, cy
                    
                    # ç•«åœ¨ mask ä¸Š
                    cv2.line(self.canvas_mask, (self.prev_x, self.prev_y), (cx, cy), BRUSH_COLOR, BRUSH_THICKNESS)
                    self.prev_x, self.prev_y = cx, cy
                    
                    # æ¸¸æ¨™é¡è‰²: ç¶ è‰² (ç¹ªåœ–ä¸­)
                    cv2.circle(frame, (cx, cy), 10, (0, 255, 0), -1)
                else:
                    # æš«åœæ¨¡å¼ï¼Œé‡ç½®ç­†ç•«èµ·é»
                    self.prev_x, self.prev_y = 0, 0
                    # æ¸¸æ¨™é¡è‰²: ç°è‰² (æš«åœä¸­)
                    cv2.circle(frame, (cx, cy), 10, (100, 100, 100), -1)
                
            else:
                # æœªåµæ¸¬åˆ°æ‰‹éƒ¨
                self.prev_x, self.prev_y = 0, 0

            # 4. å½±åƒç–ŠåŠ  (å°‡ç•«å¸ƒç–ŠåŠ åˆ°é¡é ­ç•«é¢)
            # å»ºç«‹é®ç½©
            gray_mask = cv2.cvtColor(self.canvas_mask, cv2.COLOR_BGR2GRAY)
            _, mask = cv2.threshold(gray_mask, 10, 255, cv2.THRESH_BINARY)
            mask_inv = cv2.bitwise_not(mask)
            
            # èƒŒæ™¯ (æŒ–ç©º)
            frame_bg = cv2.bitwise_and(frame, frame, mask=mask_inv)
            # å‰æ™¯ (ç·šæ¢)
            frame_fg = cv2.bitwise_and(self.canvas_mask, self.canvas_mask, mask=mask)
            # åˆä½µ
            final_frame = cv2.add(frame_bg, frame_fg)

            # 5. è½‰æ›ç‚º Tkinter æ ¼å¼ä¸¦é¡¯ç¤º
            img = Image.fromarray(cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB))
            imgtk = ImageTk.PhotoImage(image=img)
            self.video_label.imgtk = imgtk
            self.video_label.configure(image=imgtk)

        # éè¿´å‘¼å«
        self.root.after(10, self.update_frame)

    def clear_canvas(self):
        self.canvas_mask = np.zeros((480, 640, 3), dtype=np.uint8)
        self.lbl_result.config(text="é æ¸¬æ•¸å­—: ?")
        self.lbl_conf.config(text="ä¿¡å¿ƒåº¦: 0.0%")
        # æ¸…é™¤æ™‚è‡ªå‹•æš«åœï¼Œé¿å…é¦¬ä¸Šåˆç•«ä¸Šå» (å¯é¸)
        if self.is_drawing:
            self.toggle_drawing()

    def recognize_digit(self):
        # 1. å–å¾—ç•«å¸ƒå…§å®¹ (è½‰ç°éš)
        gray_canvas = cv2.cvtColor(self.canvas_mask, cv2.COLOR_BGR2GRAY)
        
        # 2. æ‰¾åˆ°æ•¸å­—çš„æœ€å°çŸ©å½¢ (Bounding Box)
        coords = cv2.findNonZero(gray_canvas)
        if coords is None:
            return # ç•«å¸ƒæ˜¯ç©ºçš„

        x, y, w, h = cv2.boundingRect(coords)
        
        # è£åˆ‡å‡ºæ•¸å­—éƒ¨åˆ†
        digit_crop = gray_canvas[y:y+h, x:x+w]
        
        if digit_crop.size == 0:
            return

        # 3. è½‰æ›ç‚º PIL Image é€²è¡Œç¸®æ”¾è™•ç†
        pil_img = Image.fromarray(digit_crop)
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œè®“é•·é‚Šè®Šæˆ 20 pixel (MNIST æ¨™æº–æ˜¯æ•¸å­—åœ¨ 20x20 å…§)
        # é€™æ¨£å¯ä»¥ç•™ 4 pixel çš„é‚Šæ¡† ( (28-20)/2 = 4 )
        max_side = max(w, h)
        scale = 20.0 / max_side
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        if new_w <= 0 or new_h <= 0:
            return
            
        # ç¸®æ”¾ (ä½¿ç”¨ High quality resizing)
        pil_img_resized = pil_img.resize((new_w, new_h), Image.Resampling.LANCZOS)
        
        # 4. å»ºç«‹ 28x28 é»‘è‰²èƒŒæ™¯
        final_img = Image.new('L', (28, 28), 0)
        
        # 5. å°‡ç¸®å°çš„æ•¸å­—è²¼åœ¨æ­£ä¸­é–“ (Center of Mass çš„ç°¡åŒ–ç‰ˆï¼šå¹¾ä½•ä¸­å¿ƒ)
        paste_x = (28 - new_w) // 2
        paste_y = (28 - new_h) // 2
        final_img.paste(pil_img_resized, (paste_x, paste_y))

        # --- æ›´æ–° Debug é è¦½è¦–çª— ---
        # æ”¾å¤§é¡¯ç¤ºï¼Œè®“ä½¿ç”¨è€…çœ‹æ¸…æ¥š
        debug_view = final_img.resize((100, 100), Image.Resampling.NEAREST)
        self.tk_debug_img = ImageTk.PhotoImage(debug_view)
        self.lbl_debug_img.configure(image=self.tk_debug_img)
        # --------------------------

        # 6. è½‰ç‚º Tensor æº–å‚™æ¨è«–
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])

        img_tensor = transform(final_img).unsqueeze(0).to(self.device)

        # 7. æ¨è«–
        with torch.no_grad():
            output = self.mnist_model(img_tensor)
            probabilities = F.softmax(output, dim=1)
            pred_prob, pred_label = torch.max(probabilities, 1)

        digit = str(pred_label.item())
        prob = pred_prob.item() * 100

        self.lbl_result.config(text=f"é æ¸¬æ•¸å­—: {digit}")
        self.lbl_conf.config(text=f"ä¿¡å¿ƒåº¦: {prob:.2f}%")

    def on_close(self):
        if self.cap.isOpened():
            self.cap.release()
        self.root.destroy()

if __name__ == "__main__":
    root = tk.Tk()
    app = GestureGUIApp(root)
    root.mainloop()
